# -*- coding: utf-8 -*-
"""Face_Recognition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MWt1I6gn3XESC63KgTJm17iWabyShP32

# **Required Libraries**
"""

# Import Necessary Libraries

import numpy as np
import torch
import torch.nn as nn
from torchvision.transforms  import transforms
from torch.utils.data import DataLoader
import torch.optim as optim
from torch.autograd import Variable
from sklearn import datasets
from sklearn.datasets import fetch_olivetti_faces
import torchvision
import pathlib
import random
import matplotlib.pyplot as plt
from torchvision.transforms import functional as F

# Check for GPU availability

gpu = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

"""# **Model Architecture:-**"""

# Define the Convolutional Neural Network model

class ConvNet(nn.Module):
  def __init__(self):
    super(ConvNet,self).__init__()

    #Layer - 1
    self.conv1 = nn.Conv2d(1, 12, 3, 1, 1)
    self.bn1 = nn.BatchNorm2d(12)
    self.relu1 = nn.ReLU()
    self.pool1 = nn.MaxPool2d(2) # 32x32

    #Layer - 2
    self.conv2 = nn.Conv2d(12, 20, 3, 1, 1)
    self.bn2 = nn.BatchNorm2d(20)
    self.relu2 = nn.ReLU()
    self.pool2 = nn.MaxPool2d(2) # 16x16

    #Layer - 3
    self.conv3 = nn.Conv2d(20, 32, 3, 1, 1)
    self.bn3 = nn.BatchNorm2d(32)
    self.pool3 = nn.MaxPool2d(2) # 8x8
    self.relu3 = nn.ReLU()

    #Final Size = 8x8x32

    self.fc1 = nn.Linear(2048,64)
    self.relu4 = nn.ReLU()
    self.fc2 = nn.Linear(64, 32)
    self.relu5 = nn.ReLU()

  def forward(self,X1,X2):
    output1 = self.conv1(X1)
    output1 = self.bn1(output1)
    output1 = self.relu1(output1)
    output1 = self.pool1(output1)
    output1 = self.conv2(output1)
    output1 = self.bn2(output1)
    output1 = self.relu2(output1)
    output1 = self.pool2(output1)
    output1 = self.conv3(output1)
    output1 = self.bn3(output1)
    output1 = self.pool3(output1)
    output1 = self.relu3(output1)
    output1 = output1.view(-1,32*8*8)
    output1 = self.fc1(output1)
    output1 = self.relu4(output1)
    output1 = self.fc2(output1)
    output1 = self.relu5(output1)

    output2 = self.conv1(X2)
    output2 = self.bn1(output2)
    output2 = self.relu1(output2)
    output2 = self.pool1(output2)
    output2 = self.conv2(output2)
    output2 = self.bn2(output2)
    output2 = self.relu2(output2)
    output2 = self.pool2(output2)
    output2 = self.conv3(output2)
    output2 = self.bn3(output2)
    output2 = self.pool3(output2)
    output2 = self.relu3(output2)
    output2 = output2.view(-1,32*8*8)
    output2 = self.fc1(output2)
    output2 = self.relu4(output2)
    output2 = self.fc2(output2)
    output2 = self.relu5(output2)

    return output1,output2

"""# **Loss Function :-**"""

# Define the Contrastive Loss function

class ContrastiveLoss(nn.Module):
    def __init__(self, margin=2):
        super(ContrastiveLoss, self).__init__()
        self.margin = margin

    def forward(self, output1, output2, target):
        euclidean_distance = torch.nn.functional.pairwise_distance(output1, output2)
        loss_contrastive = torch.mean((1 - target) * torch.pow(euclidean_distance, 2) +
                                      (target) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))

        return loss_contrastive

"""# **Dataset :-**"""

# Define a custom dataset using the Olivetti Faces dataset

from numpy.random import Generator, SFC64
from torch.utils.data import Dataset , DataLoader
class OlivettiFaces(Dataset):
  def __init__(self, data_path='/content/Data'):
    (self.data, self.target) = fetch_olivetti_faces(data_home=data_path, shuffle=False, download_if_missing=True, return_X_y=True)

  def __len__(self):
    return len(self.target)

  def __getitem__(self, index):
    if index%2 == 0:
      idx = rng.integers(low=index-index%10, high=index-index%10+10)
      img1 = self.data[idx].reshape(1,64,64)
      img2 = self.data[index].reshape(1,64,64)
      return (torch.from_numpy(img1), torch.from_numpy(img2), torch.tensor(0, dtype=torch.float32))
    else:
      idx = rng.integers(low=0, high=400)
      while (idx >= index-index%10 and idx <= index-index%10+10):
        idx = rng.integers(low=0, high=400)
      img1 = self.data[idx].reshape(1,64,64)
      img2 = self.data[index].reshape(1,64,64)
      return (torch.from_numpy(img1), torch.from_numpy(img2), torch.tensor(1, dtype=torch.float32))

rng = Generator(SFC64(12345))
Data_loader = OlivettiFaces();
train_loader = torch.utils.data.DataLoader(Data_loader, batch_size = 40, shuffle=False)
test_loader = torch.utils.data.DataLoader(Data_loader, batch_size = 400, shuffle=True)

"""# **Model :-**"""

# Initialize the model and optimizer

model=ConvNet().to(gpu)
optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.91, 0.999), eps=1e-08 ,weight_decay=0.1)
cost = ContrastiveLoss().to(gpu)

"""# **Training :-**"""

# Training loop

num_epoch = 100
losses = []
for epoch in range(num_epoch):
  for i, data in enumerate(train_loader, 0) :
      img1, img2, label = data
      img1 , img2, label = img1.to(gpu), img2.to(gpu), label.to(gpu)
      output1 , output2 = model(img1, img2)
      loss = cost(output1, output2, label)
      optimizer.zero_grad()
      loss.backward()
      optimizer.step()
      losses.append(loss.item())
      #print(loss.item())

# Plot the loss curve

plt.plot(losses)
plt.show()

"""# **Save Model**"""

torch.save(model,'/content/Path/model.pth')

"""# Testing :-"""

# Testing

for i, data in enumerate(test_loader, 0) :
    img1, img2, label = data
    img1 , img2, label = img1.to(gpu), img2.to(gpu), label.to(gpu)
correct = 0
num_images = 100

for j in range (num_images) :
  input1 = img1[j].unsqueeze(0)
  input2 = img2[j].unsqueeze(0)
  output1 , output2 = model(input1, input2)
  loss = torch.sqrt(torch.sum((output1 - output2)**2))
  #Accuracy Check
  if (loss<2):
    title = "SAME IMAGES"
    if (label[j]==0):
      correct = correct + 1;
  else:
    if (label[j]==1):
      correct = correct + 1;
    title = "DIFFERENT IMAGES"

  image1 = transforms.ToPILImage()(img1[j])
  image2 = transforms.ToPILImage()(img2[j])
  plt.figure(figsize=(3.5,3.5))
  plt.subplot(1, 2, 1)
  plt.imshow(image1,cmap='copper')
  plt.title(title)
  plt.axis('off')
  plt.subplot(1, 2, 2)
  plt.imshow(image2,cmap='copper')
  plt.tight_layout()
  plt.axis('off')
  plt.show()

"""# **Accuracy :-**

"""

# Print The Accuracy

print("Accuracy = ", correct*100/num_images,"%")